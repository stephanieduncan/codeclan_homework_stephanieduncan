---
title: "Decision Tree"
output: html_notebook
---

```{r}
library(rpart)
library(rpart.plot)
library(tidyverse)

library(janitor)
titanic_set <- read_csv('data/titanic_decision_tree_data.csv')

shuffle_index <- sample(1:nrow(titanic_set))

# shuffle the data so class order isn't in order - need this for training/testing split later on 
titanic_set <- titanic_set[shuffle_index, ]
```

Data Dictionary

- sex: Biological Sex, male or female
- age_status: adult or child (child defined as under 16)
- class : Ticket class, 1 = 1st (Upper class), 2 = 2nd (Middle Class), 3 = 3rd (Lower Class)
- port_embarkation: C = Cherbourg, Q = Queenstown, S = Southampton
- sibsp : number of siblings / spouses aboard the Titanic
- parch: number of parents / children aboard the Titanic. Some children travelled only with a nanny, therefore parch=0 for them.
- survived_flag : did they survive, 0 = No, 1 = Yes

```{r}
glimpse(titanic_set)
```

```{r}
head(titanic_set)
```


```{r}
summary(titanic_set)
```

1.1 Question 1

Cleaning up the data is always the first step. Do the following:

Take only observations which have a survived flag (i.e. that aren’t missing)
Turn your important variables into factors (sex, survived, pclass, embarkation)
Create an age_status variable which groups individuals under (and including) 16 years of age into a category called “child” category and those over 16 into a category called “adult”.
Drop the NA
Drop any variables you don’t need (X1, passenger_id, name, ticket, far, cabin)
If you need help doing this, the code is below, but please try it yourself first so you can learn!

```{r}
titanic_clean <- titanic_set %>%
  #filter by those you survived or not (removing na's)
  filter(survived %in% c(0,1)) %>%
# Convert to factor level
    mutate(sex = as.factor(sex), 
           age_status = as.factor(if_else(age <= 16, "child", "adult")),
         class = factor(pclass, levels = c(3,2,1), labels = c("Lower", "Middle", "Upper")), 
           survived_flag = factor(survived, levels = c(0,1), labels = c("No", "Yes")), 
           port_embarkation = as.factor(embarked)) %>%
  select(sex, age_status, class, port_embarkation, sib_sp, parch, survived_flag) %>%
  #omit na's
  na.omit()
```

```{r}
summary(titanic_clean)
```

1.2 Question 2

Have a look at your data and create some plots to ensure you know what you’re working with before you begin. Write a summary of what you have found in your plots. Which variables do you think might be useful to predict whether or not people are going to die? Knowing this before you start is the best way to have a sanity check that your model is doing a good job.

```{r}
library(GGally)
ggpairs(titanic_clean)
```

Sex, age_status & port embarkation against survived_flag show separation. Sib_sp does not look like it would be a significant predictor for survived_flag, not does parch.

1.3 Question 3

Now you can start to build your model. Create your testing and training set using an appropriate split. Check you have balanced sets. Write down why you chose the split you did and produce output tables to show whether or not it is balanced. [Extra - if you want to force balanced testing and training sets, have a look at the stratified() function in package splitstackshape (you can specify multiple variables to stratify on by passing a vector of variable names to the group argument, and get back testing and training sets with argument bothSets = TRUE)]

```{r}
# get how many rows we have in total to work out the percentage
n_data <- nrow(titanic_clean)

# create a test sample index
test_index <- sample(1:n_data, size = n_data*0.2)

# create test set
titanic_test  <- slice(titanic_clean, test_index)

# create training set
titanic_train <- slice(titanic_clean, -test_index)
```

I have chosen a split of 80% training data and 20% test data as there is not a lot of data (only 712 observations). If there was a much more substantial quantity of data, I would use a 90/10 split perhaps. 

```{r}
titanic_test %>%
tabyl(survived_flag)
```

```{r}
titanic_train %>%
tabyl(survived_flag)
```

The test data agrees with the training data in that the proportion of passengers who did not survive the titanic sinking are higher than those who did. However, the figures do differ between test and training output.

1.4 Question 4

Create your decision tree to try and predict survival probability using an appropriate method, and create a decision tree plot.

```{r}
titanic_fit <- rpart(
  formula = survived_flag ~ ., 
  data = titanic_train, 
  method = 'class'
)

rpart.plot(titanic_fit,
           yesno = 2, 
           fallen.leaves = TRUE, 
           faclen = 6, 
           digits = 4, 
           type = 4, 
           extra = 101)
```


1.5 Question 5

Write down what this tells you, in detail. What variables are important? What does each node tell you? Who has the highest chance of surviving? Who has the lowest? Provide as much detail as you can.

The root node predicts passengers who died overall, as the majority of passengers died. 335 died compared to only 235 who survived. Males were most likely to die - Of all males 287 died and only 75 survived. Only 48 females died and 160 survived. Middle and upper class were also likely to survive - only 7 died and 121 survived. 


1.6 Question 6

Test and add your predictions to your data. Create a confusion matrix. Write down in detail what this tells you for this specific dataset.

```{r}
library(modelr)

# add the predictions
titanic_test_pred <- titanic_test %>%
  add_predictions(titanic_fit, type = 'class')

# look at the variables 
titanic_test_pred
```

```{r}
library(yardstick)
```

Generating a confusion matrix
```{r}
conf_mat <- titanic_test_pred %>%
              conf_mat(truth = survived_flag, estimate = pred)

conf_mat
```

The confusion matrix shows that the ‘correct’ predictions, i.e. true negatives and true positives are on the top left to bottom right diagonal.
The ‘incorrect’ predictions, i.e. false negatives and false positives are on the bottom left to top right diagonal. A perfect classifier would have zeroes on this diagonal.

In this example:-

- TP - it was predicted that 79 passengers died and they did.
- TN - it was predicted 31 passengers survived and they died.
- FP - it was predicted 22 passengers died but they survived.
- FN - it was predicted 10 passengers survived but they died.
that 31 passengers were predicted to survived


```{r}
accuracy <- titanic_test_pred %>%
 accuracy(truth = survived_flag, estimate = pred)

accuracy 
```

```{r}
titanic_test_pred %>%
  sensitivity(truth = survived_flag, estimate = pred)
```

```{r}
titanic_test_pred %>%
  specificity(truth = survived_flag, estimate = pred)
```

```{r}
library(caret)

confusionMatrix(titanic_test_pred$pred, titanic_test_pred$survived_flag)
#order is estimate and then truth 
```

Accuracy of test data - 77.46%
Sensitivity (TP rate) - 88.76%
Specifity (TN rate) - 58.49%